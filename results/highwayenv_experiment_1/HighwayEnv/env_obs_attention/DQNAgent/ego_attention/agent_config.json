{"model": {"type": "EgoAttentionNetwork", "layers": [256, 256], "embedding_layer": {"type": "MultiLayerPerceptron", "layers": [64, 64], "reshape": false, "in": 7, "activation": "RELU", "out": null}, "others_embedding_layer": {"type": "MultiLayerPerceptron", "layers": [64, 64], "reshape": false, "in": 7, "activation": "RELU", "out": null}, "self_attention_layer": null, "attention_layer": {"type": "EgoAttention", "feature_size": 64, "heads": 2, "dropout_factor": 0}, "output_layer": {"type": "MultiLayerPerceptron", "layers": [64, 64], "reshape": false, "in": 64, "out": 5, "activation": "RELU"}, "in": 105, "out": 5, "presence_feature_idx": 0}, "optimizer": {"type": "ADAM", "lr": 0.0005, "weight_decay": 0, "k": 5}, "loss_function": "l2", "memory_capacity": 15000, "batch_size": 64, "gamma": 0.99, "device": "cuda:best", "exploration": {"method": "EpsilonGreedy", "tau": 6000, "temperature": 1.0, "final_temperature": 0.05}, "target_update": 512, "double": true, "__class__": "<class 'rl_agents.agents.deep_q_network.pytorch.DQNAgent'>", "n_steps": 1}